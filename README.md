# ML-Practice
<br/>机器学习实战实践<br/><br/>

## k-近邻算法
<p>k-近邻算法用于监督学习，根据不同特征值之间的距离对数据进行分类</p>
<h3>1. 公式</h3>
<p>knn距离计算公式：</p>
<img src="https://github.com/ch135/ML-Practice/blob/master/img/knn_formula.png"/>
<p>归一化公式：</p>
<img src="https://github.com/ch135/ML-Practice/blob/master/img/normalization.png"/>
<h3>2. 缺点</h3>
<p>1.数据较大时，易消耗内存</p>
<p>2.必须计算每个数据距离，比较耗时</p>
<p>3.无法给出任何数据的基本结构信息，无法知晓平均实例样本和典型实例样本有什么特征</p>
